{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12e0099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:31:34.665879Z",
     "iopub.status.busy": "2023-03-12T23:31:34.665624Z",
     "iopub.status.idle": "2023-03-12T23:31:35.687342Z",
     "shell.execute_reply": "2023-03-12T23:31:35.686622Z"
    },
    "papermill": {
     "duration": 1.035782,
     "end_time": "2023-03-12T23:31:35.692636",
     "exception": false,
     "start_time": "2023-03-12T23:31:34.656854",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as com\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import savgol_filter, find_peaks\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from random import shuffle, uniform\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31521a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:31:35.728894Z",
     "iopub.status.busy": "2023-03-12T23:31:35.728525Z",
     "iopub.status.idle": "2023-03-12T23:31:37.866575Z",
     "shell.execute_reply": "2023-03-12T23:31:37.863546Z"
    },
    "papermill": {
     "duration": 2.16028,
     "end_time": "2023-03-12T23:31:37.868626",
     "exception": false,
     "start_time": "2023-03-12T23:31:35.708346",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Brian2 import\n",
    "import brian2 as b2\n",
    "\n",
    "b2.set_device('cpp_standalone')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "b2.defaultclock.dt = 0.05*b2.ms\n",
    "clock_dt = b2.defaultclock.dt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5d3a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:31:37.889232Z",
     "iopub.status.busy": "2023-03-12T23:31:37.888513Z",
     "iopub.status.idle": "2023-03-12T23:31:37.895229Z",
     "shell.execute_reply": "2023-03-12T23:31:37.893486Z"
    },
    "papermill": {
     "duration": 0.026222,
     "end_time": "2023-03-12T23:31:37.902725",
     "exception": false,
     "start_time": "2023-03-12T23:31:37.876503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "include_state_monitor = {}\n",
    "include_state_monitor['Input'] = False\n",
    "include_state_monitor['Neurons'] = False\n",
    "include_state_monitor['Small'] = False\n",
    "include_state_monitor['Synapses'] = False\n",
    "include_state_monitor['Output'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf8b5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_rate = 100\n",
    "vth_ = -57\n",
    "\n",
    "training_foldername = 'training_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89bac0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "\n",
    "N_per_edge = 20                         #number of input neurons per dimension\n",
    "refract_in = 0                          #input neurons refractory period (ms)\n",
    "in_zone_d = (1/(N_per_edge-1)) + (1e-6) #distance between two consecutive points \n",
    "                                        #in a straight line with N_per_edge \n",
    "                                        #equidistant points distributed along the line\n",
    "\n",
    "## WTA\n",
    "\n",
    "N_o = 61                                #number of neurons per sensor\n",
    "resting_time = 50                       #resting time (ms)\n",
    "V_rest = -65                            #resting potential (mV)\n",
    "V_reset = -65                           #reset potential (mV)\n",
    "V_th = {}                           \n",
    "V_th['Gyroscope'] = vth_                #gyroscope neurons base threshold potential time (mV)\n",
    "V_th['Accelerometer'] = vth_            #accelerometer neurons base threshold potential time (mV)\n",
    "tau_r = 10                              #refractory period  (ms)\n",
    "d_vt = 3.0                              #adaptive threshold increment (mV)\n",
    "tauvt = 400                             #adaptive threshold decay time constant (ms)\n",
    "tau_m = 30                              #membrane time constant (ms)\n",
    "tau_I_m = 5                             #input excitatory current time constant (ms)\n",
    "tau_I_i = 20                            #input inhibitory current time constant (ms)\n",
    "R_m = 1                                 #excitatory membrane resistance (ohm)\n",
    "R_i = 1                                 #inhibitory membrane resistance (ohm)\n",
    "\n",
    "\n",
    "## INPUT -> WTA (excitatory synapses with trace-based STDP)\n",
    "\n",
    "taupre = 20.0                       #presynaptic activity trace time constant (ms) \n",
    "taupost = 20.0                      #postsynaptic activity trace time constant (ms)\n",
    "Apre = 0.02                         #maximum weight modification for LTP\n",
    "Apost = - 1.05 * Apre               #maximum weight modification for LTD\n",
    "\n",
    "w_e = 20.0                          #excitatory current increment  (mA)\n",
    "w_i = 1                             #inhibitory current increment  (mA)\n",
    "wmax = 1.0                          #maximum value of weights between input and wta layer\n",
    "initial_weight_coef = 0.15          #the weights are initialized randomly with values in [0, initial_weight_coef]\n",
    "\n",
    "\n",
    "## WTA -> WTA (lateral inhibitory synapses)\n",
    "\n",
    "tau_inh = 10                        #inhibition duration (ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68c245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_rest *= b2.mV\n",
    "V_reset *= b2.mV\n",
    "V_th['Gyroscope'] *= b2.mV\n",
    "V_th['Accelerometer'] *= b2.mV\n",
    "#V_th *= mV\n",
    "tau_m *= b2.ms\n",
    "tau_I_m *= b2.ms\n",
    "tauvt *= b2.ms\n",
    "tau_I_i *= b2.ms\n",
    "R_m *= b2.ohm\n",
    "R_i *= b2.ohm\n",
    "w_e *= b2.mA\n",
    "w_i *= b2.mA\n",
    "tau_r *= b2.ms\n",
    "d_vt *= b2.mV\n",
    "taupre *= b2.ms\n",
    "taupost *= b2.ms\n",
    "tau_inh *= b2.ms\n",
    "refract_in *= b2.ms\n",
    "resting_time *= b2.ms\n",
    "in_rate *= b2.Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a94317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:31.853118Z",
     "iopub.status.busy": "2023-03-12T23:26:31.852598Z",
     "iopub.status.idle": "2023-03-12T23:26:31.857210Z",
     "shell.execute_reply": "2023-03-12T23:26:31.856136Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if include_state_monitor['Input'] or include_state_monitor['Neurons'] or include_state_monitor['Output']:\n",
    "    n_samples = 2\n",
    "    n_reps_per_sample = 1\n",
    "else:\n",
    "    n_samples = 50\n",
    "    n_reps_per_sample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bf8596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:31.895317Z",
     "iopub.status.busy": "2023-03-12T23:26:31.895004Z",
     "iopub.status.idle": "2023-03-12T23:26:31.906650Z",
     "shell.execute_reply": "2023-03-12T23:26:31.905591Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evenly distributed neurons within a cubea\n",
    "class Nube:\n",
    "    i = 0\n",
    "    def __init__(self, n_nodes):\n",
    "        self.n = n_nodes**3\n",
    "        self.neighbour_dst = 2 / (n_nodes - 1)\n",
    "        \n",
    "        ps = np.linspace(-1,1,n_nodes)\n",
    "        self.coordinates = [[[(x_,y_,z_) for z_ in ps] for y_ in ps] for x_ in ps]\n",
    "        self.coordinates = [item for sublist in self.coordinates for item in sublist]\n",
    "        self.coordinates = [item for sublist in self.coordinates for item in sublist]\n",
    "        self.coordinates = {index: pos for index, pos in enumerate(self.coordinates)}\n",
    "        self.x = [pos[0] for pos in self.coordinates.values()]\n",
    "        self.y = [pos[1] for pos in self.coordinates.values()]\n",
    "        self.z = [pos[2] for pos in self.coordinates.values()]\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "    def scatter_neurons(self, ax):\n",
    "        for n in range(self.n):\n",
    "            x_,y_,z_ = self.coordinates[n]\n",
    "            ax.scatter(x_,y_,z_, alpha = 0.5, c = 'cornflowerblue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb058b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:31.927208Z",
     "iopub.status.busy": "2023-03-12T23:26:31.926639Z",
     "iopub.status.idle": "2023-03-12T23:26:31.937234Z",
     "shell.execute_reply": "2023-03-12T23:26:31.935987Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trial(dir_):\n",
    "    \n",
    "    g_x = []\n",
    "    g_y = []\n",
    "    g_z = []\n",
    "    a_x = []\n",
    "    a_y = []\n",
    "    a_z = []\n",
    "    tt = []\n",
    "\n",
    "    file1 = open(dir_, 'r')\n",
    "\n",
    "    lines = file1.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "            word = line.split()\n",
    "            try:\n",
    "                    g_x.append(float(word[0]))\n",
    "                    g_y.append(float(word[1]))\n",
    "                    g_z.append(float(word[2]))\n",
    "                    a_x.append(float(word[3]))\n",
    "                    a_y.append(float(word[4]))\n",
    "                    a_z.append(float(word[5]))\n",
    "                    tt.append(float(word[6]))\n",
    "            except:\n",
    "                    pass\n",
    "    file1.close()\n",
    "\n",
    "    #data = pd.DataFrame([g_x,g_y,g_z, a_x,a_y,a_z])\n",
    "    #data = data.transpose()\n",
    "    #data.columns = ['gx', 'gy', 'gz', 'ax', 'ay', 'az']\n",
    "\n",
    "    sensor_data = [g_x,g_y,g_z, a_x,a_y,a_z,tt]\n",
    "\n",
    "    #for a,axis in enumerate(sensor_data):\n",
    "    #    if a < 6:\n",
    "    #        sensor_data[a][0] = 0\n",
    "    #        sensor_data[a] = [value - axis[v-1] for v,value in enumerate(axis)]\n",
    "            \n",
    "    return [g_x,g_y,g_z, a_x,a_y,a_z,tt] #, data\n",
    "\n",
    "def normalize_axis(s_axis):\n",
    "    \n",
    "    ret = [[] for s in s_axis]\n",
    "    \n",
    "    ret = s_axis.copy()\n",
    "    \n",
    "    for a,axis in enumerate(ret):\n",
    "        for v, value in enumerate(axis):\n",
    "            \n",
    "            if ret[a][v] < 0:\n",
    "                ret[a][v] = ret[a][v]/(32768)    # + 32767)\n",
    "            else:\n",
    "                ret[a][v] = ret[a][v]/(32767)   #+ 32768)\n",
    "    \n",
    "    return ret\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc63eeb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:31.972833Z",
     "iopub.status.busy": "2023-03-12T23:26:31.972547Z",
     "iopub.status.idle": "2023-03-12T23:26:31.978691Z",
     "shell.execute_reply": "2023-03-12T23:26:31.977935Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_ = os.path.join(os.getcwd(), 'Dataset')\n",
    "n_axis = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59edf44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:32.024521Z",
     "iopub.status.busy": "2023-03-12T23:26:32.024257Z",
     "iopub.status.idle": "2023-03-12T23:26:32.040015Z",
     "shell.execute_reply": "2023-03-12T23:26:32.028548Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_frequency = 400*b2.Hz\n",
    "desired_frequency = 100*b2.Hz\n",
    "\n",
    "downFreqN = int(sample_frequency/desired_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9817bbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:32.069772Z",
     "iopub.status.busy": "2023-03-12T23:26:32.068586Z",
     "iopub.status.idle": "2023-03-12T23:26:34.701455Z",
     "shell.execute_reply": "2023-03-12T23:26:34.700235Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in place\n",
      "86.57894736842105\n",
      "83.97560975609755\n",
      "86.23076923076923\n",
      "85.05263157894737\n",
      "85.55263157894737\n",
      "81.7948717948718\n",
      "Torso rotation\n",
      "189.48888888888888\n",
      "179.02564102564102\n",
      "179.57894736842104\n",
      "174.16666666666666\n",
      "179.28205128205127\n",
      "171.5\n",
      "Jumping jacks\n",
      "91.70454545454545\n",
      "93.62162162162163\n",
      "94.10810810810811\n",
      "89.07894736842105\n",
      "92.25\n",
      "91.32432432432432\n",
      "Touch feet\n",
      "174.3846153846154\n",
      "159.6153846153846\n",
      "166.78571428571428\n",
      "162.8\n",
      "156.35714285714286\n",
      "160.64285714285714\n",
      "159.42857142857142\n",
      "161.42857142857142\n",
      "167.57142857142858\n",
      "166.76923076923077\n",
      "165.76923076923077\n",
      "173.07142857142858\n",
      "165.5\n",
      "166.30769230769232\n",
      "167.92857142857142\n",
      "169.23076923076923\n"
     ]
    }
   ],
   "source": [
    "idxs = [[] for m in range(len(os.listdir(dir_)))]\n",
    "movements_name = [[] for m in range(len(os.listdir(dir_)))]\n",
    "samples = [[[] for n in range(n_axis)] for m in range(len(os.listdir(dir_)))]\n",
    "\n",
    "series = [[] for m in movements_name]\n",
    "data = [[] for m in movements_name]\n",
    "\n",
    "for m, movement in enumerate(os.listdir(dir_)):\n",
    "\n",
    "    #fig = plt.figure(figsize=(10, 9))\n",
    "    #axs = []\n",
    "    #for a in range(6):\n",
    "    #    axs.append(fig.add_subplot(6, 1 , a+1))\n",
    "    \n",
    "    \n",
    "    print(movement)\n",
    "    movements_name[m] = movement\n",
    "    \n",
    "    movement_path = os.path.join(dir_, movement)\n",
    "    \n",
    "    n_trials = len(os.listdir(movement_path))\n",
    "    \n",
    "    idxs[m] = [[] for n in range(n_trials)]\n",
    "\n",
    "    if 'Jumping' in movement:\n",
    "        is_sin_like_axis = 0\n",
    "        n_filters = 1\n",
    "    elif 'Torso' in movement:\n",
    "        is_sin_like_axis = 2\n",
    "        n_filters = 1\n",
    "    elif 'Running' in movement:\n",
    "        is_sin_like_axis = 2\n",
    "        n_filters = 1\n",
    "    elif 'Touch' in movement:\n",
    "        is_sin_like_axis = 2\n",
    "        n_filters = 1\n",
    "    else:\n",
    "        print(movement)\n",
    "\n",
    "    for tri, trial in enumerate(sorted(os.listdir(movement_path))):\n",
    "\n",
    "\n",
    "        #[gx, gy, gz, ax, ay, az, t], _ = load_trial(os.path.join(movement_path, trial))\n",
    "        [gx, gy, gz, ax, ay, az, dt] = load_trial(os.path.join(movement_path, trial))\n",
    "\n",
    "\n",
    "        \n",
    "        sensors_axis = [gx, gy, gz, ax, ay, az]\n",
    "        sensors_axis = normalize_axis(sensors_axis)\n",
    "\n",
    "        # is_sin_like_axis = index of axis in sensor_axis (0 : g_x, 1 : g_y, ..., 5 : a_z)\n",
    "        # n_filters : number of times axis is filtered                \n",
    "        \n",
    "\n",
    "        #fig = plt.figure(figsize=(30, 20))\n",
    "        #axs = []\n",
    "\n",
    "        \n",
    "\n",
    "        init_th = .3\n",
    "        init = 0\n",
    "        for i, val in enumerate(sensors_axis[is_sin_like_axis]):\n",
    "            if val > init_th:\n",
    "                init = i\n",
    "                break\n",
    "            \n",
    "        _axis = [[] for a in range(len(sensors_axis))]\n",
    "        for a,_ in enumerate(sensors_axis):\n",
    "            _axis[a] = sensors_axis[a][init:]\n",
    "\n",
    "        #for a, axis in enumerate(_axis):\n",
    "        #    axs.append(fig.add_subplot(6, 1 , a+1))\n",
    "        #    axs[-1].plot(np.arange(len(axis)), axis)\n",
    "        \n",
    "        filtered = savgol_filter(_axis[is_sin_like_axis], 51, 3)\n",
    "        \n",
    "        \n",
    "        for n in range(n_filters):\n",
    "            filtered = savgol_filter(filtered, 51, 3)\n",
    "\n",
    "        #axs[is_sin_like_axis].plot(np.arange(len(filtered)), filtered)\n",
    "        \n",
    "        peaks = find_peaks(filtered, height=0)[0][1:-2]\n",
    "        #diffs = [peaks[p+1]-peak for p, peak in enumerate(peaks[:-1])]\n",
    "        #for p in peaks:\n",
    "        #    axs[is_sin_like_axis].axvline(x=p, lw=0.75, c='black')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        #for p, peak in enumerate(peaks[2:-2]):\n",
    "        #    idxs[m][t].append((peak, peaks[p+2]))\n",
    "        \n",
    "        avg_peak_dst = sum([peaks[p+1]-peak for p,peak in enumerate(peaks[:-1])])/(len(peaks)-1)\n",
    "        print(avg_peak_dst)\n",
    "\n",
    "        for p, peak in enumerate(peaks[:-1]):\n",
    "            series_i= np.zeros((len(_axis), int(peaks[p+1]-peak)))\n",
    "            for a, axis in enumerate(_axis):\n",
    "                if peaks[p+1]-peak>0.85*avg_peak_dst and peaks[p+1]-peak<1.15*avg_peak_dst: \n",
    "                    series_i[a] = np.array(axis[peak:peaks[p+1]])\n",
    "\n",
    "                    sample = np.array(axis[peak:peaks[p+1]])\n",
    "                    #diff_sample = [value - sample[v-1] for v,value in enumerate(sample[1:], start=1)]\n",
    "                    #sample = [0 for val in sample]\n",
    "                    samples[m][a].append(sample)\n",
    "\n",
    "                    #axs[a].plot(np.arange(len(sample)), sample)\n",
    "            series[m].append(series_i)\n",
    "            \n",
    "    #plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a1d0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:34.756401Z",
     "iopub.status.busy": "2023-03-12T23:26:34.756058Z",
     "iopub.status.idle": "2023-03-12T23:26:34.761023Z",
     "shell.execute_reply": "2023-03-12T23:26:34.759919Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movement Running in place has 229 samples\n",
      "Movement Torso rotation has 254 samples\n",
      "Movement Jumping jacks has 224 samples\n",
      "Movement Touch feet has 219 samples\n"
     ]
    }
   ],
   "source": [
    "for m,movement in enumerate(movements_name):\n",
    "    print(f'Movement {movement} has {len(samples[m][0])} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e060c009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:34.792418Z",
     "iopub.status.busy": "2023-03-12T23:26:34.790830Z",
     "iopub.status.idle": "2023-03-12T23:26:34.796328Z",
     "shell.execute_reply": "2023-03-12T23:26:34.795643Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sensors = {'Gyroscope':[0,1,2], 'Accelerometer':[3,4,5]}\n",
    "axis = {0:'x', 3:'x',1:'y', 4:'y',2:'z', 5:'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17dd5743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:34.879583Z",
     "iopub.status.busy": "2023-03-12T23:26:34.879185Z",
     "iopub.status.idle": "2023-03-12T23:26:34.942945Z",
     "shell.execute_reply": "2023-03-12T23:26:34.941008Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "resting_array = [0.0 for _ in range(int(resting_time/(1/desired_frequency)))]\n",
    "\n",
    "\n",
    "nu = Nube(N_per_edge)\n",
    "\n",
    "N_i = nu.n\n",
    "Input = {}\n",
    "InputSpikeMonitor = {}\n",
    "InputStateMonitor = {}\n",
    "InputMonitor = {}\n",
    "InputRateMonitor = {}\n",
    "\n",
    "Synapse = {}\n",
    "\n",
    "\n",
    "\n",
    "pattern_dt = 1/desired_frequency\n",
    "elapsed_time=0*b2.ms\n",
    "x = {sensor : [] for sensor in sensors}\n",
    "y = {sensor : [] for sensor in sensors}\n",
    "z = {sensor : [] for sensor in sensors}\n",
    "\n",
    "\n",
    "begins = []\n",
    "durations = []\n",
    "movement_index = []\n",
    "\n",
    "iteration = []\n",
    "it = 1\n",
    "\n",
    "iteration_begin = []\n",
    "\n",
    "movement_it = []\n",
    "\n",
    "learning = []\n",
    "\n",
    "events = [0,1,2,3,4,5]\n",
    "event_type = {sensor: [] for sensor in sensors}\n",
    "\n",
    "\n",
    "\n",
    "#for n in range(n_reps_per_sample):\n",
    "for sp in range(n_samples):\n",
    "    for m,movement in enumerate(movements_name):\n",
    "        for s,sensor in enumerate(sensors):\n",
    "            \n",
    "            axis_x = sensors[sensor][0]\n",
    "            axis_y = sensors[sensor][1]\n",
    "            axis_z = sensors[sensor][2]\n",
    "\n",
    "            x[sensor].extend(samples[m][axis_x][-1-sp])\n",
    "            x[sensor].extend([x[sensor][-1] for r in range(len(resting_array))])\n",
    "\n",
    "            y[sensor].extend(samples[m][axis_y][-1-sp])\n",
    "            y[sensor].extend([y[sensor][-1] for r in range(len(resting_array))])\n",
    "\n",
    "            z[sensor].extend(samples[m][axis_z][-1-sp])\n",
    "            z[sensor].extend([z[sensor][-1] for r in range(len(resting_array))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sample_duration = len(samples[m][axis_x][-1-sp])\n",
    "        \n",
    "        learning.extend([1.0 for _ in range(int(sample_duration))])\n",
    "        learning.extend([-1 for _ in range(len(resting_array))])\n",
    "\n",
    "        iteration.extend([it for _ in range(int(sample_duration))])\n",
    "        iteration.extend(resting_array)\n",
    "\n",
    "        iteration_begin.extend([elapsed_time for _ in range(int(sample_duration))])\n",
    "        iteration_begin.extend(resting_array)\n",
    "\n",
    "        movement_it.extend([m for _ in range(int(sample_duration))])\n",
    "        movement_it.extend([m for _ in range(len(resting_array))])\n",
    "\n",
    "        begins.append(elapsed_time)\n",
    "        durations.append(sample_duration*pattern_dt)\n",
    "        movement_index.append(m)\n",
    "\n",
    "        elapsed_time += sample_duration * pattern_dt + resting_time\n",
    "\n",
    "    \n",
    "\n",
    "    it += 1\n",
    "\n",
    "is_learning = b2.TimedArray(learning, dt=pattern_dt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a765e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T23:26:34.971181Z",
     "iopub.status.busy": "2023-03-12T23:26:34.970930Z",
     "iopub.status.idle": "2023-03-12T23:26:34.992536Z",
     "shell.execute_reply": "2023-03-12T23:26:34.990613Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_sensor_0 = b2.TimedArray(x['Gyroscope'], dt=(1/desired_frequency))\n",
    "y_sensor_0 = b2.TimedArray(y['Gyroscope'], dt=(1/desired_frequency))\n",
    "z_sensor_0 = b2.TimedArray(z['Gyroscope'], dt=(1/desired_frequency))\n",
    "\n",
    "x_sensor_1 = b2.TimedArray(x['Accelerometer'], dt=(1/desired_frequency))\n",
    "y_sensor_1 = b2.TimedArray(y['Accelerometer'], dt=(1/desired_frequency))\n",
    "z_sensor_1 = b2.TimedArray(z['Accelerometer'], dt=(1/desired_frequency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c363f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_duration = [0 for m in movements_name]\n",
    "for m,movement in enumerate(movements_name):        \n",
    "\n",
    "    movement_duration[m] = len(samples[m][0])*pattern_dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6da546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dir = 'training_output'\n",
    "training_dir = training_foldername\n",
    "weights_dt = 5*b2.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1e55ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d02c1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(time, voltage, nr_connections):\n",
    "\n",
    "    colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "\n",
    "    starts = [begin for begin in begins if begin < time[-1]]\n",
    "\n",
    "    max_v_per_iteration = {n:{s: -1  for s in range(len(starts))} for n in range(len(movements_name))}\n",
    "\n",
    "    ths = {}\n",
    "\n",
    "    accuracy = {m: 0 for m in range(len(movements_name))}\n",
    "    false_pos = {m: {n: 0 for n in range(len(movements_name))} for m in range(len(movements_name))}\n",
    "\n",
    "    for s,start_time in enumerate(starts):\n",
    "        \n",
    "        end_time = start_time + durations[s]\n",
    "        start_idx = time.searchsorted(start_time)\n",
    "        end_idx = time.searchsorted(end_time)\n",
    "\n",
    "\n",
    "        maxs = {}\n",
    "        for neuron, v in enumerate(voltage):\n",
    "            maxs[neuron] = max(v[start_idx:end_idx])/nr_connections[neuron]\n",
    "        \n",
    "        max_v = max(maxs.values())\n",
    "\n",
    "\n",
    "        if max_v > 0.0:\n",
    "            max_neuron = list(maxs.values()).index(max_v)\n",
    "            if max_neuron == movement_index[s]:\n",
    "                accuracy[movement_index[s]] += 1\n",
    "            else:\n",
    "                false_pos[movement_index[s]][max_neuron] += 1\n",
    "\n",
    "    print(accuracy)\n",
    "    print(false_pos)\n",
    "\n",
    "    for m in range(len(movements_name)):\n",
    "        accuracy[m] /= n_samples\n",
    "        accuracy[m] *= 100\n",
    "        for n in range(len(movements_name)):\n",
    "            false_pos[m][n] /= n_samples\n",
    "            false_pos[m][n] *= 100\n",
    "\n",
    "\n",
    "    print(accuracy)\n",
    "    print(false_pos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return accuracy, false_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1231263",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c46cec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   This function implements the two possible testing iterations\n",
    "#   delays : synaptic delays calculated in first iteration\n",
    "#   spikes : wta neurons spikes recorded from last iteration\n",
    "#\n",
    "#   If delays and spikes are empty, the function will perform the first iteration. Otherwise it performs the second. The testing set is used for both iterations.\n",
    "#\n",
    "#   First iteration     :   determining wta --> recognition connections and corresponding delays.\n",
    "#                           a network similar to the learning stage is used. \n",
    "#                           for each pattern presentation, the first spike from each wta neuron is considered.\n",
    "#                           for each pattern, if a wta neuron shows a similar firing time (relative to the start of a pattern)\n",
    "#                           across all the testing set, a delayed connection is established between this wta neuron and the corresponding \n",
    "#                           recognition neuron. The requirement for a wta to be selected are:\n",
    "#                               - it must fire 90% of the times for a specific movement\n",
    "#                               - its firing times must all be close enough to the mean of all the firing times (for a specific movement)\n",
    "#                           the delays are calculated from the mean of firing times. the thesis document details how\n",
    "#                           \n",
    "#                           \n",
    "#   Second iteration    :   assess the network performance.\n",
    "#                           a simpler network is used with just two layers: wta and recognition.\n",
    "#                           the wta layer is implement with a SpikeGeneratorGroup. the wta firing times were recorded it the first iteration.\n",
    "#                           there are as many recognitions neurons as the number of movements (4 in this case).\n",
    "#                           each movement pattern presentantion is said to be correctly recognized if its corresponding recognition neuron \n",
    "#                           exhibits the highest membrane potential during the pattern presentation \n",
    "                          \n",
    "\n",
    "def simulate(delays={}, spikes={}):\n",
    "\n",
    "    \n",
    "\n",
    "    b2.device.reinit()\n",
    "    b2.device.activate()\n",
    "\n",
    "    testing_delays = False                  \n",
    "    testing_accuracy = False\n",
    "\n",
    "    if delays=={} and spikes=={}:\n",
    "        # determining wta --> recognition connections and corresponding delays\n",
    "        \n",
    "        # not sure if cpp_standalone accelerates the simulation\n",
    "        # can use runtime as well\n",
    "        b2.set_device('cpp_standalone')\n",
    "        testing_delays = True\n",
    "    if delays!={} and spikes!={}:\n",
    "        # assess the network performance\n",
    "        b2.set_device('runtime')        \n",
    "        testing_accuracy = True\n",
    "    \n",
    "    \n",
    "    net = b2.Network()\n",
    "\n",
    "    # wta neuron equations\n",
    "    neuron_eqs = '''\n",
    "    dv/dt = ((V_rest-v) + R_m*I_m - R_i*I_i)/tau_m : volt (unless refractory)\n",
    "    dI_m/dt = -I_m/tau_I_m : amp\n",
    "    dI_i/dt = -I_i/tau_I_i : amp\n",
    "    dvt/dt = (Vth-vt)/(tauvt) : volt\n",
    "    inhibited : boolean\n",
    "    Vth : volt\n",
    "    '''\n",
    "    reset = '''\n",
    "    vt = v + d_vt\n",
    "    v=V_reset\n",
    "    I_m = 0*amp\n",
    "    '''\n",
    "\n",
    "    neurons = {}\n",
    "    NeuronsSpikeMonitor = {}\n",
    "    NeuronsStateMonitor = {}\n",
    "    inhibition = {}\n",
    "    inhibition_0 = {}\n",
    "\n",
    "    \n",
    "\n",
    "    InputNeuronsSynapse = {}\n",
    "    InputNeuronsSynapseMonitor = {}\n",
    "\n",
    "    if testing_delays:\n",
    "        # set up a network similar to training\n",
    "        # refer to the training notebook for comments on this\n",
    "        for s, sensor in enumerate(sensors):\n",
    "            Input[sensor] = b2.NeuronGroup(N_i, \n",
    "                                            '''\n",
    "                                            zone_fire : Hz\n",
    "                                            min_fire = 0.05*Hz : Hz\n",
    "                                            x : 1   (constant)\n",
    "                                            y : 1   (constant)\n",
    "                                            z : 1   (constant)\n",
    "                                            x_t = x_sensor_''' +str(s)+ '''(t) : 1 (shared)\n",
    "                                            y_t = y_sensor_''' +str(s)+ '''(t) : 1 (shared)\n",
    "                                            z_t = z_sensor_''' +str(s)+ '''(t) : 1 (shared)\n",
    "                                            er = (abs(x_t-x)/2) + (abs(y_t-y)/2) + (abs(z_t-z)/2) : 1\n",
    "                                            in_zone = er <= in_zone_d*sqrt(3) : boolean   (constant over dt)\n",
    "                                            ''',\n",
    "                                            threshold='(rand()<min_fire*dt or (in_zone and rand()<zone_fire*dt)) and is_learning(t)==1',\n",
    "                                            refractory=refract_in,\n",
    "                                            method='euler')\n",
    "\n",
    "            Input[sensor].zone_fire = in_rate\n",
    "            Input[sensor].x = nu.x\n",
    "            Input[sensor].y = nu.y\n",
    "            Input[sensor].z = nu.z\n",
    "            \n",
    "            net.add(Input[sensor])\n",
    "            \n",
    "            InputSpikeMonitor[sensor] = b2.SpikeMonitor(Input[sensor])\n",
    "            net.add(InputSpikeMonitor[sensor])\n",
    "\n",
    "            neurons[sensor] = b2.NeuronGroup(N_o, model=neuron_eqs,\n",
    "                                threshold='v>vt and not(inhibited)', reset=reset,\n",
    "                                refractory='tau_r', method='euler')\n",
    "\n",
    "            neurons[sensor].v = 'V_rest'\n",
    "            neurons[sensor].vt = V_th[sensor]\n",
    "            neurons[sensor].Vth = V_th[sensor]\n",
    "\n",
    "            neurons[sensor].I_m = '0*amp'\n",
    "            neurons[sensor].I_i = '0*amp'\n",
    "            neurons[sensor].inhibited = False\n",
    "            neurons[sensor].run_regularly('v = v*int(is_learning(t)==1) + V_rest*int(not(is_learning(t)==1))', dt=pattern_dt)\n",
    "            neurons[sensor].run_regularly('vt = vt*int(is_learning(t)==1) + Vth*int(not(is_learning(t)==1))', dt=pattern_dt)\n",
    "            \n",
    "\n",
    "\n",
    "            net.add(neurons[sensor])\n",
    "\n",
    "            NeuronsSpikeMonitor[sensor] = b2.SpikeMonitor(neurons[sensor])\n",
    "            net.add(NeuronsSpikeMonitor[sensor])\n",
    "\n",
    "            inhibition[sensor] = b2.Synapses(neurons[sensor], neurons[sensor], \n",
    "                                        on_pre='''I_i_post = clip(I_i_post + w_i, 0*amp, I_i_post + w_i)\n",
    "                                                inhibited_post = True''')\n",
    "            inhibition_0[sensor] = b2.Synapses(neurons[sensor], neurons[sensor], \n",
    "                                            on_pre='inhibited_post = False')\n",
    "\n",
    "            inhibition[sensor].connect('i!=j')\n",
    "            inhibition_0[sensor].connect('i!=j')\n",
    "            inhibition_0[sensor].delay = tau_inh\n",
    "\n",
    "            net.add(inhibition[sensor])\n",
    "            net.add(inhibition_0[sensor])\n",
    "\n",
    "            \n",
    "\n",
    "            # the weights are now static and equal to a set if recorded weights during training\n",
    "            InputNeuronsSynapse[sensor] = b2.Synapses(Input[sensor], neurons[sensor],  'w : 1',\n",
    "                                                on_pre='I_m_post = I_m_post + w*w_e*(not_refractory_post)*int(not(inhibited_post))')\n",
    "\n",
    "            InputNeuronsSynapse[sensor].connect()\n",
    "            InputNeuronsSynapse[sensor].w = weights[sensor]     # assign the recorded weights (explained below)\n",
    "            net.add(InputNeuronsSynapse[sensor])   \n",
    "\n",
    "    if testing_delays:\n",
    "\n",
    "        # to estimate the delay we'll just return the wta firings\n",
    "        # we also return the input spikes if there's anything we want to do with it\n",
    "\n",
    "        net.run(elapsed_time)\n",
    "        \n",
    "        delays_ = {sensor : {output_neuron :{ input_neuron: -1 for input_neuron in range(N_o)} for output_neuron in range(len(movements_name))} for sensor in sensors}        \n",
    "        \n",
    "        return delays_, {sensor: {'i':InputSpikeMonitor[sensor].i[:],'t':InputSpikeMonitor[sensor].t[:]} for sensor in sensors},  {sensor: {'i':NeuronsSpikeMonitor[sensor].i[:],'t':NeuronsSpikeMonitor[sensor].t[:], 'spike_trains':NeuronsSpikeMonitor[sensor].spike_trains()} for sensor in sensors}, net\n",
    "\n",
    "    elif testing_accuracy:\n",
    "\n",
    "        # set up recognition layer\n",
    "        # leaky and integrate neurons\n",
    "\n",
    "        \n",
    "        NeuronsOutputSynapse= {}\n",
    "        output_tau = [40, 40, 40, 40]*b2.ms\n",
    "        output_vth = [100, 100, 100, 100]       # v never > 100 --> neurons don't fire. can also remove threshold condition\n",
    "        \n",
    "\n",
    "\n",
    "        output = b2.NeuronGroup(len(movements_name), '''dv/dt = -v/tau : 1\n",
    "                                                        vth : 1\n",
    "                                                        tau : second''', threshold='v > vth', reset='v=0', method='exact')\n",
    "        output.vth = output_vth\n",
    "        output.tau = output_tau\n",
    "        OutputSpikeMonitor = b2.SpikeMonitor(output)\n",
    "        net.add(output)\n",
    "        net.add(OutputSpikeMonitor)\n",
    "        #OutputStateMonitor = b2.StateMonitor(output, ['v'] ,record=True)\n",
    "        #net.add(OutputStateMonitor)\n",
    "\n",
    "        connected = False #indicates if any of the sensors has connections\n",
    "\n",
    "        n_connections = {m: 0 for m in range(len(movements_name))}\n",
    "        for sensor in sensors:\n",
    "\n",
    "            # create a SpikeGeneratorGroup with the wta firing times of the first testing interation\n",
    "            neurons[sensor] = b2.SpikeGeneratorGroup(N_o, spikes[sensor]['i'], spikes[sensor]['t'])            \n",
    "            net.add(neurons[sensor])           \n",
    "            \n",
    "\n",
    "            # create synapses between wta and recognition neurons\n",
    "            NeuronsOutputSynapse[sensor] = b2.Synapses(neurons[sensor], output, \n",
    "                                                     '''w : 1''',\n",
    "                                                        on_pre = ''' v_post += w\n",
    "                                                        ''')\n",
    "            \n",
    "            sconnected = False  #indicates if this sensor has connections\n",
    "            \n",
    "            # for each wta neuron\n",
    "            for n in range(N_o):\n",
    "                # for each recognition neuron                                                            \n",
    "                for m in range(len(movements_name)): \n",
    "                    # each delay in 'delays' is initiallized without units\n",
    "                    # if it has units of type second, it means there is a delayed connection \n",
    "                    # between wta neuron with index n and recognition neuron with index m\n",
    "                    if type(delays[sensor][m][n]) == type(0*b2.ms):\n",
    "                        \n",
    "                        NeuronsOutputSynapse[sensor].connect(i=n, j=m)\n",
    "                        NeuronsOutputSynapse[sensor].delay[n,m] = delays[sensor][m][n]\n",
    "\n",
    "                        n_connections[m] += 1   # we save the number of connections per sensor\n",
    "                                                # to later divide each recognition neuron potential\n",
    "                                                # by the number of connections it receives\n",
    "\n",
    "                        sconnected = True       # the are connections for this sensor\n",
    "                        \n",
    "            # if the sensor has connections\n",
    "            if sconnected:\n",
    "                NeuronsOutputSynapse[sensor].w = 1   \n",
    "\n",
    "                net.add(NeuronsOutputSynapse[sensor])\n",
    "            \n",
    "            connected = connected or sconnected\n",
    "\n",
    "\n",
    "        # record the potential of recognitions neurons \n",
    "        OutputStateMonitor = b2.StateMonitor(output, ['v'], record=np.arange(output.N), dt= 0.5*b2.ms)\n",
    "        net.add(OutputStateMonitor)\n",
    "\n",
    "        net.run(elapsed_time)\n",
    "\n",
    "        # get_accuracy() will check if each recognition neuron had the highest potential\n",
    "        # when presented with its corresponding movement\n",
    "        # acc : % times each recognition neuron fired to its corresponding movement\n",
    "        # flspstv : false positives (a recognition neuron firing for another movement)\n",
    "        acc, flspstv = get_accuracy(OutputStateMonitor.t[:], OutputStateMonitor.v[:], n_connections)\n",
    "        del net\n",
    "\n",
    "        return (acc, flspstv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232c9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'time_window_begin' : list stores the start time of each pattern presentation\n",
    "# 'dts'               : list stores the duration time of each pattern\n",
    "# \n",
    "#  Return the index i of the element in 'time_window_begin' such that time_instant is in the interval [time_window_begin[i], time_window_begin[i]+dts[i]]\n",
    "def get_b(time_instant, time_window_begin, dts):\n",
    "    for ti in range(len(time_window_begin)):\n",
    "        if time_instant >= time_window_begin[ti] and time_instant <= time_window_begin[ti] + dts[ti]:\n",
    "            return ti    \n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc5c7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = ['red', 'green', 'black', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8456e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "\n",
    "    d = []\n",
    "    results = []\n",
    "\n",
    "    # we'll load the weights from the training output\n",
    "    # first we see how many weight recordings there are\n",
    "    # the file has following structure:\n",
    "    # recording_time0 weight0 weight1 weight 2 ...\n",
    "    # recording_time1 weight0 weight1 weight 2 ...\n",
    "    #\n",
    "    # n_ws : number of recordings\n",
    "    # last_w_dt : \n",
    "    with open(os.path.join(training_dir, 'weights_'+'Gyroscope'+'.txt'), 'r') as f:\n",
    "        for l,line in enumerate(f):\n",
    "            pass\n",
    "            \n",
    "        n_ws = l + 1\n",
    "        last_w_dt = int(line.split()[0])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # the recordings time instants\n",
    "    w_recordings = np.linspace(0, last_w_dt, n_ws,endpoint=True, dtype=int)\n",
    "\n",
    "    # the recordings occurs at every 5 seconds (can be changed in the training notebook)\n",
    "    # which yields a large number of recordings\n",
    "    # to test a smaller number of recordings, or a specific recording\n",
    "    # we should determine the recording time instants we want to test\n",
    "    # and save it in w_recordings. note that the available time instants are multiples of the \n",
    "    # weight recording time period (in this case 0, 5, 10, 15... seconds)\n",
    "    # just manipulate the existing values in w_recordings to include the recordings you want\n",
    "    \n",
    "    # w_recordings = [w_recordings[0]]   -> tests the first weight recording\n",
    "    # w_recordings = [w_recordings[-1]]  -> tests the last weight recording\n",
    "    # w_recordings = w_recordings[::20]  -> tests every 20th the weight recording \n",
    "\n",
    "    # another way is to set a new weight recording time period\n",
    "    # and get the corresponding slicer\n",
    "\n",
    "    # recording_dt = 5*b2.second\n",
    "    # test_w_dt = 40*b2.second\n",
    "    # new_recording_dt_k = int(test_w_dt/recording_dt)\n",
    "    # for r, recording in enumerate(w_recordings[::new_recording_dt_k]):\n",
    "    #   ...\n",
    "    # \n",
    "    # here we're just going to test against the last recording\n",
    "\n",
    "    w_recordings = [w_recordings[-1]]\n",
    "    \n",
    "    # perform test for each considered weight recording\n",
    "    for r, recording in enumerate(w_recordings):\n",
    "    \n",
    "        print(f'Recorded at {recording} s (/{last_w_dt} s)')\n",
    "\n",
    "        \n",
    "        \n",
    "        delays_ = {sensor : {output_neuron :{ input_neuron: -1 for input_neuron in range(N_o)} for output_neuron in range(len(movements_name))} for sensor in sensors}\n",
    "        delays = {sensor : {output_neuron :{ input_neuron: -1 for input_neuron in range(N_o)} for output_neuron in range(len(movements_name))} for sensor in sensors}\n",
    "\n",
    "        # for each sensor, fetch the weight recording at save it in 'weights'\n",
    "        for sensor in sensors:\n",
    "            with open(os.path.join(training_dir, 'weights_'+sensor+'.txt'), 'r') as f:\n",
    "                for l,line in enumerate(f):\n",
    "                    if int(line.split()[0])==recording:\n",
    "                        weights[sensor] = [float(w_) for w_ in line.split()[1:]]\n",
    "                        break\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        # perform first testing iteration\n",
    "        # get delayed connections and wta firing times           \n",
    "        delays, inputSpikes, wta_spikes, net_ = simulate()\n",
    "        del net_        \n",
    "\n",
    "        \n",
    "        connected = False       # will be True if there are connections for any of the sensors\n",
    "        for sensor in sensors:\n",
    "\n",
    "            spiketrains = wta_spikes[sensor]['spike_trains']    #wta neuron spike times            \n",
    "            first_spikes_by_neuron = {m: {n: {} for n in range(N_o)} for m in range(len(movements_name))}\n",
    "\n",
    "            # for each pattern presentation\n",
    "            for b, start_time in enumerate(begins):\n",
    "\n",
    "                end_time = start_time + durations[b]                \n",
    "                m = movement_index[b]\n",
    "\n",
    "                # for each wta neuron, get the first spike that lies in the interval [start_time, end_time]\n",
    "                for j in range(len(spiketrains)):\n",
    "                    neuron_spikes = spiketrains[j]\n",
    "                    spikes_in_interval = neuron_spikes[(neuron_spikes >= start_time) & (neuron_spikes < end_time)]\n",
    "\n",
    "                    # if there is any spike, save the firing time difference \n",
    "                    # since the beggining of the pattern presentation\n",
    "                    if len(spikes_in_interval) > 0:\n",
    "                        first_spike_time = spikes_in_interval[0]\n",
    "                        first_spikes_by_neuron[m][j][b] = first_spike_time - start_time\n",
    "\n",
    "            # now we have the the time it took for each wta neuron to fire after being presented with a specific movement\n",
    "            # the first spikes are saved as per movement/ per wta neuron index / per index of pattern presentation\n",
    "            # we'll organize them per wta neuron index / per index of movement presented\n",
    "            sconnected = False # will be True if there are connections for the current sensor\n",
    "            for j in range(N_o):\n",
    "                \n",
    "                # get wta neuron number number of fires for each movement (each movement is presented n_samples times, i.e. has n_samples patterns)\n",
    "                n_fires = [len(list(first_spikes_by_neuron[m][j].values())) for m in range(len(movements_name))]\n",
    "                # check if wta neuron j fired 90% of times for each movement\n",
    "                n_fires_own = [n_fires[m]>0.9*n_samples for m in range(len(movements_name))]\n",
    "                \n",
    "                # for each movement\n",
    "                for mov_index, f in enumerate(n_fires_own):\n",
    "                    # if neurons fired 90% times\n",
    "                    if f==True:\n",
    "                        # calculate the average firing time of neuron j for movement with index mov_index\n",
    "                        spikes = list(first_spikes_by_neuron[mov_index][j].values()) \n",
    "                        average_firing_time = sum(spikes)/len(spikes)\n",
    "\n",
    "                        # calculate the deviation of firing times relative to the average firing time\n",
    "                        dts = [abs(spike-average_firing_time) for spike in spikes]                        \n",
    "                        dtmean = (sum(dts)/len(dts))/pattern_dt\n",
    "\n",
    "                        # if the deviation is small enough\n",
    "                        if dtmean < 15:\n",
    "                            # set the delay to equal to the average firing time\n",
    "                            delays_[sensor][mov_index][j] = average_firing_time\n",
    "\n",
    "        \n",
    "        # we need to calculate the final delays\n",
    "        # for each movement, we get the highest average firing time (consider it is the neuron with index n)\n",
    "        # and add a delay to the remaining neurons such that :\n",
    "        #   highest_average_firing_time = wta_average_firing_time[n]\n",
    "        #   wta_average_firing_time[j] + delay[j] = highest_average_firing_time <=> delay[j] = highest_average_firing_time - wta_average_firing_time[j]\n",
    "        mconnected = {}\n",
    "        for  m in range(len(movements_name)):\n",
    "            movement_delays = [[d for d in delays_[sensor][m].values() if type(d)==type(0*b2.ms)] for sensor in sensors]\n",
    "\n",
    "            movement_delays = [delay for sensor in movement_delays for delay in sensor]\n",
    "\n",
    "            if len(movement_delays) > 0:\n",
    "                max_fire = max(movement_delays)\n",
    "                for n in range(N_o):\n",
    "                    for sensor in sensors:\n",
    "                        d = delays_[sensor][m][n]\n",
    "                        if type(d)==type(0*b2.ms):\n",
    "                            delays[sensor][m][n] = max_fire - d\n",
    "                            print(sensor, m,n, delays[sensor][m][n])\n",
    "                            \n",
    "                            mconnected[m] = True\n",
    "            else:\n",
    "                mconnected[m] = False\n",
    "                        \n",
    "                \n",
    "        mconnected = list(mconnected.values())\n",
    "        connected = all(mconnected)\n",
    "        \n",
    "        # if the simulation yielded results i.e. any wta neuron showed a regular behavior\n",
    "        #                                        and delays were determined \n",
    "        if connected:\n",
    "            # perform second test iteration\n",
    "            # get accuracy and save it\n",
    "            result = simulate(delays, wta_spikes)\n",
    "            results.append(result)\n",
    "\n",
    "        # if no delayed connections were established\n",
    "        # save an empty result\n",
    "        else:\n",
    "            for m, conn in enumerate(mconnected):\n",
    "                if not(conn):\n",
    "                    print(f'Movement {movements_name[m]} has no connections')\n",
    "            \n",
    "            accu = {m: 0 for m in range(len(movements_name))}\n",
    "            falsep = {m: {n: 0 for n in range(len(movements_name))} for m in range(len(movements_name))}\n",
    "\n",
    "            results.append((accu, falsep))\n",
    "        \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41231ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded at 815 s (/815 s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    \"i\" is an internal variable of group \"synapses\", but also exists in the run namespace with the value 271. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    \"i\" is an internal variable of group \"synapses_1\", but also exists in the run namespace with the value 271. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    \"i\" is an internal variable of group \"synapses_3\", but also exists in the run namespace with the value 271. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
      "WARNING    \"i\" is an internal variable of group \"synapses_4\", but also exists in the run namespace with the value 271. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerometer 0 0 0.3793551 s\n",
      "Accelerometer 0 5 0.5003231 s\n",
      "Gyroscope 0 6 0.4432911 s\n",
      "Accelerometer 0 8 0.3307131 s\n",
      "Accelerometer 0 12 0.4818151 s\n",
      "Accelerometer 0 14 0.41670204 s\n",
      "Accelerometer 0 16 0.35378571 s\n",
      "Gyroscope 0 17 262.93710204 ms\n",
      "Accelerometer 0 19 0.3618851 s\n",
      "Gyroscope 0 23 0.43742802 s\n",
      "Accelerometer 0 23 0.4717271 s\n",
      "Gyroscope 0 24 167.29423248 ms\n",
      "Gyroscope 0 26 0. s\n",
      "Accelerometer 0 27 0.44044677 s\n",
      "Accelerometer 0 29 0.3805511 s\n",
      "Accelerometer 0 30 291.79910204 ms\n",
      "Accelerometer 0 31 83.41510204 ms\n",
      "Gyroscope 0 34 0.32539978 s\n",
      "Accelerometer 0 37 169.61632653 ms\n",
      "Gyroscope 0 38 0.44315714 s\n",
      "Accelerometer 0 38 0.43202802 s\n",
      "Accelerometer 0 39 3.69339991 ms\n",
      "Accelerometer 0 42 0.4374731 s\n",
      "Gyroscope 0 43 202.79310204 ms\n",
      "Gyroscope 0 44 145.78218537 ms\n",
      "Accelerometer 0 45 0.43117249 s\n",
      "Accelerometer 0 46 0.3599871 s\n",
      "Accelerometer 0 48 0.4172371 s\n",
      "Accelerometer 0 49 288.98510204 ms\n",
      "Accelerometer 0 53 0.3389951 s\n",
      "Gyroscope 0 58 0.43902684 s\n",
      "Accelerometer 0 58 0.46085302 s\n",
      "Gyroscope 1 0 0.78035172 s\n",
      "Accelerometer 1 2 1.11951269 s\n",
      "Gyroscope 1 4 0.89677669 s\n",
      "Gyroscope 1 5 0.91763265 s\n",
      "Accelerometer 1 5 1.20224082 s\n",
      "Gyroscope 1 7 0.97410869 s\n",
      "Accelerometer 1 8 0.91657469 s\n",
      "Accelerometer 1 9 0. s\n",
      "Accelerometer 1 12 1.21227469 s\n",
      "Accelerometer 1 13 1.11271069 s\n",
      "Accelerometer 1 16 0.86932011 s\n",
      "Accelerometer 1 17 1.02149388 s\n",
      "Gyroscope 1 20 0.55435597 s\n",
      "Accelerometer 1 20 4.18069388 ms\n",
      "Accelerometer 1 22 1.19909869 s\n",
      "Accelerometer 1 23 1.21953869 s\n",
      "Gyroscope 1 24 0.64081469 s\n",
      "Accelerometer 1 24 1.17776069 s\n",
      "Gyroscope 1 26 0.93965269 s\n",
      "Gyroscope 1 29 1.11164082 s\n",
      "Accelerometer 1 32 1.19953069 s\n",
      "Accelerometer 1 33 1.03634286 s\n",
      "Gyroscope 1 34 0.65706869 s\n",
      "Gyroscope 1 35 1.01935869 s\n",
      "Accelerometer 1 36 1.06078252 s\n",
      "Accelerometer 1 38 1.04863669 s\n",
      "Accelerometer 1 39 1.18324469 s\n",
      "Gyroscope 1 40 1.04689669 s\n",
      "Accelerometer 1 41 9.79001303 ms\n",
      "Gyroscope 1 44 0.89758469 s\n",
      "Accelerometer 1 45 1.05334669 s\n",
      "Gyroscope 1 50 0.78016669 s\n",
      "Gyroscope 1 51 0.65871669 s\n",
      "Accelerometer 1 51 1.01205172 s\n",
      "Gyroscope 1 52 0.92836469 s\n",
      "Gyroscope 1 54 0.71369592 s\n",
      "Gyroscope 1 60 0.73271269 s\n",
      "Accelerometer 1 60 66.06530612 ms\n",
      "Gyroscope 2 0 308.878 ms\n",
      "Gyroscope 2 1 0.37427765 s\n",
      "Gyroscope 2 5 0.39474 s\n",
      "Accelerometer 2 5 0.362654 s\n",
      "Gyroscope 2 7 0.323458 s\n",
      "Accelerometer 2 7 273.196 ms\n",
      "Accelerometer 2 8 298.182 ms\n",
      "Accelerometer 2 12 0.42754 s\n",
      "Gyroscope 2 13 103.89658333 ms\n",
      "Accelerometer 2 14 0.363714 s\n",
      "Accelerometer 2 17 296.08825 ms\n",
      "Accelerometer 2 19 0.415686 s\n",
      "Gyroscope 2 21 0.368834 s\n",
      "Accelerometer 2 23 0.396078 s\n",
      "Gyroscope 2 24 71.484 ms\n",
      "Accelerometer 2 27 0.379042 s\n",
      "Accelerometer 2 31 243.082 ms\n",
      "Accelerometer 2 32 285.598 ms\n",
      "Accelerometer 2 33 231.807 ms\n",
      "Gyroscope 2 34 0.4038586 s\n",
      "Gyroscope 2 35 0.328426 s\n",
      "Gyroscope 2 37 220.818 ms\n",
      "Accelerometer 2 37 250.284 ms\n",
      "Accelerometer 2 38 270.328 ms\n",
      "Accelerometer 2 39 0.34275 s\n",
      "Gyroscope 2 42 271.686 ms\n",
      "Gyroscope 2 45 83.23914286 ms\n",
      "Accelerometer 2 45 0. s\n",
      "Accelerometer 2 48 0.41873 s\n",
      "Gyroscope 2 49 70.72077551 ms\n",
      "Gyroscope 2 50 148.23 ms\n",
      "Accelerometer 2 55 0.365426 s\n",
      "Gyroscope 2 56 0.327562 s\n",
      "Gyroscope 3 0 0.70503243 s\n",
      "Accelerometer 3 1 0.78275643 s\n",
      "Gyroscope 3 2 1.06763043 s\n",
      "Gyroscope 3 3 0.40229574 s\n",
      "Accelerometer 3 3 1.12909643 s\n",
      "Gyroscope 3 4 0.95374451 s\n",
      "Gyroscope 3 5 0.91224643 s\n",
      "Gyroscope 3 7 0.85181243 s\n",
      "Gyroscope 3 10 0.43518043 s\n",
      "Accelerometer 3 12 1.02098443 s\n",
      "Accelerometer 3 15 1.15193843 s\n",
      "Accelerometer 3 18 0. s\n",
      "Accelerometer 3 19 0.83720043 s\n",
      "Gyroscope 3 21 0.9614234 s\n",
      "Accelerometer 3 21 1.03139243 s\n",
      "Gyroscope 3 24 0.52580643 s\n",
      "Gyroscope 3 26 0.84769349 s\n",
      "Accelerometer 3 26 1.05027643 s\n",
      "Accelerometer 3 27 71.63042553 ms\n",
      "Accelerometer 3 28 1.11483443 s\n",
      "Accelerometer 3 29 48.98042553 ms\n",
      "Accelerometer 3 32 52.50851064 ms\n",
      "Accelerometer 3 33 48.27511941 ms\n",
      "Accelerometer 3 34 1.10611843 s\n",
      "Gyroscope 3 35 0.86699443 s\n",
      "Accelerometer 3 39 0.91730843 s\n",
      "Accelerometer 3 40 1.07454243 s\n",
      "Accelerometer 3 41 1.13211243 s\n",
      "Accelerometer 3 42 1.07989643 s\n",
      "Gyroscope 3 43 0.55350643 s\n",
      "Gyroscope 3 44 0.75485471 s\n",
      "Gyroscope 3 45 1.11373043 s\n",
      "Accelerometer 3 45 39.71642553 ms\n",
      "Gyroscope 3 46 0.98177043 s\n",
      "Accelerometer 3 47 1.11599843 s\n",
      "Gyroscope 3 51 0.35159553 s\n",
      "Gyroscope 3 52 0.82500777 s\n",
      "Gyroscope 3 55 0.35227308 s\n",
      "Gyroscope 3 56 0.79173043 s\n",
      "Gyroscope 3 58 1.07439243 s\n",
      "Gyroscope 3 59 0.65564247 s\n",
      "{0: 50, 1: 50, 2: 50, 3: 49}\n",
      "{0: {0: 0, 1: 0, 2: 0, 3: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0}, 3: {0: 1, 1: 0, 2: 0, 3: 0}}\n",
      "{0: 100.0, 1: 100.0, 2: 100.0, 3: 98.0}\n",
      "{0: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 1: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 2: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 3: {0: 2.0, 1: 0.0, 2: 0.0, 3: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "r = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa396ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({0: 100.0, 1: 100.0, 2: 100.0, 3: 98.0},\n",
       "  {0: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
       "   1: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
       "   2: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
       "   3: {0: 2.0, 1: 0.0, 2: 0.0, 3: 0.0}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43153006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot the evolution of the network recognition performance overtime\n",
    "def plot_results(results):\n",
    "\n",
    "    clrs = ['red', 'green', 'orange']\n",
    "    ls = ['solid','dashed', 'dashdotdotted']\n",
    "    markers = [\"o\", \"D\", \"s\", '']\n",
    "\n",
    "    fp = {}\n",
    "\n",
    "    for neuron in range(len(movements_name)):\n",
    "        acc_neuron = [(r_,result[0][neuron]) for r_,result in enumerate(results)]\n",
    "        x, y = zip(*acc_neuron)\n",
    "        \n",
    "\n",
    "        plt.scatter(x,y, c='black')\n",
    "\n",
    "        fp_neuron = [result[1] for result in results]\n",
    "\n",
    "        fp[neuron] = {m: [] for m in range(len(movements_name)) if m!=neuron}\n",
    "\n",
    "        for f, fp_ in enumerate(fp_neuron):\n",
    "            for m in range(len(movements_name)):\n",
    "                if m != neuron:\n",
    "                    fp[neuron][m].append(fp_[m][neuron])\n",
    "                    plt.plot(f, fp_[m][neuron], c=clrs[neuron], ms=5, alpha=.4)\n",
    "                    #plt.scatter(f, fp_[m][neuron], marker=markers[m],c=clrs[neuron])\n",
    "    \n",
    "\n",
    "    \n",
    "    acc = [sum(list(acc_.values()))/len(movements_name) for (acc_, _) in results]\n",
    "    plt.plot(np.arange(len(acc)), acc, 'o-b', ms=5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "606afa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({0: 100.0, 1: 100.0, 2: 100.0, 3: 98.0}, {0: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 1: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 2: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}, 3: {0: 2.0, 1: 0.0, 2: 0.0, 3: 0.0}})]\n"
     ]
    }
   ],
   "source": [
    "if len(r) > 1:\n",
    "    plot_results(r)\n",
    "else:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb8b66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResults = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2cf2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveResults:\n",
    "    with open(os.path.join(training_dir,\"results.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(r, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.156628,
   "end_time": "2023-03-12T23:31:38.896487",
   "environment_variables": {},
   "exception": true,
   "input_path": "inzone_one_output.ipynb",
   "output_path": "inzone_one_output.ipynb",
   "parameters": {
    "Apre": "0.04",
    "filename": "Apre"
   },
   "start_time": "2023-03-12T23:31:32.739859",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
